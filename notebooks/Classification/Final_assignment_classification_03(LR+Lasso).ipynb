{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598ff010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages always been used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preprocessing useful function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Data scaling\n",
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function for spilting training & testing data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Function for hyper-parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Functions for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f445bb4",
   "metadata": {},
   "source": [
    "# 3. Data scaling with minimax technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5439a552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X1_1</th>\n",
       "      <th>X1_2</th>\n",
       "      <th>X3_0</th>\n",
       "      <th>X3_1</th>\n",
       "      <th>X4_0</th>\n",
       "      <th>X4_1</th>\n",
       "      <th>X5_0</th>\n",
       "      <th>...</th>\n",
       "      <th>X6_3</th>\n",
       "      <th>X6_4</th>\n",
       "      <th>X6_5</th>\n",
       "      <th>X7_1</th>\n",
       "      <th>X7_2</th>\n",
       "      <th>X10_1</th>\n",
       "      <th>X10_2</th>\n",
       "      <th>X10_3</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>82</td>\n",
       "      <td>71.97</td>\n",
       "      <td>28.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>57</td>\n",
       "      <td>77.93</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>81</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>35</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>51</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3425 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X2      X8    X9  X1_1  X1_2  X3_0  X3_1  X4_0  X4_1  X5_0  ...  X6_3  \\\n",
       "0     67  228.69  36.6     1     0     1     0     0     1     0  ...     1   \n",
       "1     80  105.92  32.5     1     0     1     0     0     1     0  ...     1   \n",
       "2     49  171.23  34.4     0     1     1     0     1     0     0  ...     1   \n",
       "3     79  174.12  24.0     0     1     0     1     1     0     0  ...     0   \n",
       "4     81  186.21  29.0     1     0     1     0     1     0     0  ...     1   \n",
       "...   ..     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "3420  82   71.97  28.3     1     0     0     1     1     0     0  ...     0   \n",
       "3421  57   77.93  21.7     0     1     1     0     1     0     0  ...     1   \n",
       "3422  81  125.20  40.0     0     1     1     0     1     0     0  ...     0   \n",
       "3423  35   82.99  30.6     0     1     1     0     1     0     0  ...     0   \n",
       "3424  51  166.29  25.6     1     0     1     0     1     0     0  ...     1   \n",
       "\n",
       "      X6_4  X6_5  X7_1  X7_2  X10_1  X10_2  X10_3  Y_0  Y_1  \n",
       "0        0     0     0     1      0      1      0    0    1  \n",
       "1        0     0     1     0      1      0      0    0    1  \n",
       "2        0     0     0     1      0      0      1    0    1  \n",
       "3        1     0     1     0      1      0      0    0    1  \n",
       "4        0     0     0     1      0      1      0    0    1  \n",
       "...    ...   ...   ...   ...    ...    ...    ...  ...  ...  \n",
       "3420     1     0     1     0      1      0      0    1    0  \n",
       "3421     0     0     1     0      1      0      0    1    0  \n",
       "3422     1     0     0     1      1      0      0    1    0  \n",
       "3423     1     0     1     0      1      0      0    1    0  \n",
       "3424     0     0     1     0      0      1      0    1    0  \n",
       "\n",
       "[3425 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data(sometimes need to use \"/\")\n",
    "dummied_new_df = pd.read_csv('C:/Users/user/Desktop/Final_assignment/Data/中風_deleteNA_dummies.csv')\n",
    "dummied_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775616d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X1_1</th>\n",
       "      <th>X1_2</th>\n",
       "      <th>X3_0</th>\n",
       "      <th>X3_1</th>\n",
       "      <th>X4_0</th>\n",
       "      <th>X4_1</th>\n",
       "      <th>X5_0</th>\n",
       "      <th>...</th>\n",
       "      <th>X6_3</th>\n",
       "      <th>X6_4</th>\n",
       "      <th>X6_5</th>\n",
       "      <th>X7_1</th>\n",
       "      <th>X7_2</th>\n",
       "      <th>X10_1</th>\n",
       "      <th>X10_2</th>\n",
       "      <th>X10_3</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.311801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.234512</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.536008</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.605161</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X2        X8        X9  X1_1  X1_2  X3_0  X3_1  X4_0  X4_1  X5_0  \\\n",
       "0  0.791667  0.801265  0.311801   1.0   0.0   1.0   0.0   0.0   1.0   0.0   \n",
       "1  0.972222  0.234512  0.260870   1.0   0.0   1.0   0.0   0.0   1.0   0.0   \n",
       "2  0.541667  0.536008  0.284472   0.0   1.0   1.0   0.0   1.0   0.0   0.0   \n",
       "3  0.958333  0.549349  0.155280   0.0   1.0   0.0   1.0   1.0   0.0   0.0   \n",
       "4  0.986111  0.605161  0.217391   1.0   0.0   1.0   0.0   1.0   0.0   0.0   \n",
       "\n",
       "   ...  X6_3  X6_4  X6_5  X7_1  X7_2  X10_1  X10_2  X10_3  Y_0  Y_1  \n",
       "0  ...   1.0   0.0   0.0   0.0   1.0    0.0    1.0    0.0  0.0  1.0  \n",
       "1  ...   1.0   0.0   0.0   1.0   0.0    1.0    0.0    0.0  0.0  1.0  \n",
       "2  ...   1.0   0.0   0.0   0.0   1.0    0.0    0.0    1.0  0.0  1.0  \n",
       "3  ...   0.0   1.0   0.0   1.0   0.0    1.0    0.0    0.0  0.0  1.0  \n",
       "4  ...   1.0   0.0   0.0   0.0   1.0    0.0    1.0    0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minimax scaling\n",
    "MMscaler=MinMaxScaler(feature_range=(0, 1))\n",
    "scaling=MMscaler.fit_transform(dummied_new_df)\n",
    "scaled_data=pd.DataFrame(data=scaling)\n",
    "scaled_data.columns=['X2','X8','X9','X1_1','X1_2','X3_0','X3_1','X4_0','X4_1','X5_0','X5_1','X6_1','X6_2','X6_3','X6_4','X6_5','X7_1','X7_2','X10_1','X10_2','X10_3','Y_0','Y_1'\n",
    "]\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e1143",
   "metadata": {},
   "source": [
    "# 4. Set dependent variable(Y or target) & independent variable(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710857ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set x (make prediction) with minimax\n",
    "scaled_x=scaled_data.drop(['Y_0','Y_1'],axis=1).copy()\n",
    "#set y (want to predict)\n",
    "scaled_y=scaled_data['Y_1'].copy()\n",
    "scaled_y=scaled_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003fca54",
   "metadata": {},
   "source": [
    "# 5.  Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff0f643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.80385946 0.80339191 0.80323227 0.80271618 0.80259943\n",
      " 0.80253555 0.80241541 0.80256572 0.80252342 0.80245313        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "random_state= 1\n",
      "Training score: 0.8038594594030289\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.758\n",
      "Precision:   0.163\n",
      "Sensitivity: 0.941\n",
      "Specificity: 0.748\n",
      "F1 score:    0.278\n",
      "AUC:         0.9\n",
      "ThresHold:   0.059632443379063316\n",
      "-----------------------------------\n",
      "[[487 164]\n",
      " [  2  32]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.81954767 0.81987467 0.81995428 0.81985292 0.81979939\n",
      " 0.81959319 0.81949499 0.8193913  0.81935853 0.81933562        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2\n",
      "random_state= 2\n",
      "Training score: 0.8199542802581501\n",
      "Best Hyper-parameter set: {'C': 3}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.777\n",
      "Precision:   0.192\n",
      "Sensitivity: 0.773\n",
      "Specificity: 0.777\n",
      "F1 score:    0.308\n",
      "AUC:         0.833\n",
      "ThresHold:   0.05612310510206977\n",
      "-----------------------------------\n",
      "[[498 143]\n",
      " [ 10  34]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83097402 0.83094178 0.8312141  0.83131038 0.83138591\n",
      " 0.83143148 0.83141524 0.83137738 0.83151454 0.8315796         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3\n",
      "random_state= 3\n",
      "Training score: 0.8315795967640751\n",
      "Best Hyper-parameter set: {'C': 10}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.712\n",
      "Precision:   0.12\n",
      "Sensitivity: 0.788\n",
      "Specificity: 0.709\n",
      "F1 score:    0.209\n",
      "AUC:         0.789\n",
      "ThresHold:   0.05749952369655645\n",
      "-----------------------------------\n",
      "[[462 190]\n",
      " [  7  26]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83252717 0.83201085 0.83174517 0.83140819 0.83143418\n",
      " 0.83135123 0.83112608 0.8310532  0.83102613 0.83100907        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4\n",
      "random_state= 4\n",
      "Training score: 0.8325271670945655\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.628\n",
      "Precision:   0.106\n",
      "Sensitivity: 0.909\n",
      "Specificity: 0.613\n",
      "F1 score:    0.19\n",
      "AUC:         0.794\n",
      "ThresHold:   0.0337069957608293\n",
      "-----------------------------------\n",
      "[[400 252]\n",
      " [  3  30]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82622376 0.82538658 0.82444931 0.82392356 0.82373537\n",
      " 0.8236947  0.82361225 0.82349318 0.82349157 0.82350897        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5\n",
      "random_state= 5\n",
      "Training score: 0.8262237553742127\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.747\n",
      "Precision:   0.145\n",
      "Sensitivity: 0.778\n",
      "Specificity: 0.746\n",
      "F1 score:    0.245\n",
      "AUC:         0.791\n",
      "ThresHold:   0.056267829517054425\n",
      "-----------------------------------\n",
      "[[484 165]\n",
      " [  8  28]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82363988 0.82312285 0.82301549 0.82272286 0.82269461\n",
      " 0.8226612  0.82256119 0.82259199 0.82254666 0.82248811        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 6\n",
      "random_state= 6\n",
      "Training score: 0.8236398766185202\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.666\n",
      "Precision:   0.146\n",
      "Sensitivity: 0.864\n",
      "Specificity: 0.652\n",
      "F1 score:    0.249\n",
      "AUC:         0.814\n",
      "ThresHold:   0.03248643434207559\n",
      "-----------------------------------\n",
      "[[418 223]\n",
      " [  6  38]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.81838724 0.81817251 0.81768616 0.81743822 0.81740328\n",
      " 0.81729484 0.81731306 0.81731422 0.81731956 0.81737313        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 7\n",
      "random_state= 7\n",
      "Training score: 0.8183872390199503\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.831\n",
      "Precision:   0.16\n",
      "Sensitivity: 0.778\n",
      "Specificity: 0.833\n",
      "F1 score:    0.266\n",
      "AUC:         0.848\n",
      "ThresHold:   0.11301048451997416\n",
      "-----------------------------------\n",
      "[[548 110]\n",
      " [  6  21]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82500037 0.82497058 0.82489154 0.8247188  0.82465404\n",
      " 0.82470259 0.82453572 0.8244509  0.82436325 0.82435601        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 8\n",
      "random_state= 8\n",
      "Training score: 0.8250003710902567\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.689\n",
      "Precision:   0.13\n",
      "Sensitivity: 0.861\n",
      "Specificity: 0.68\n",
      "F1 score:    0.225\n",
      "AUC:         0.806\n",
      "ThresHold:   0.04442023177683714\n",
      "-----------------------------------\n",
      "[[441 208]\n",
      " [  5  31]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82404376 0.82404535 0.82427524 0.82428    0.8245801\n",
      " 0.82455416 0.82465461 0.82460418 0.82455402 0.82445911        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 9\n",
      "random_state= 9\n",
      "Training score: 0.8246546126834055\n",
      "Best Hyper-parameter set: {'C': 7}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.631\n",
      "Precision:   0.113\n",
      "Sensitivity: 0.914\n",
      "Specificity: 0.615\n",
      "F1 score:    0.202\n",
      "AUC:         0.819\n",
      "ThresHold:   0.03178267379364426\n",
      "-----------------------------------\n",
      "[[400 250]\n",
      " [  3  32]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 10\n",
      "random_state= 10\n",
      "Training score: 0.8322878429561152\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.726\n",
      "Precision:   0.144\n",
      "Sensitivity: 0.75\n",
      "Specificity: 0.724\n",
      "F1 score:    0.242\n",
      "AUC:         0.788\n",
      "ThresHold:   0.05826891266035165\n",
      "-----------------------------------\n",
      "[[467 178]\n",
      " [ 10  30]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Best: 0.831\n",
      "Best Round: 7\n",
      "---------------------------------------\n",
      "Accuracy_mean: 0.716 ,Accuracy_std: 0.06\n",
      "Precision_mean: 0.142 ,Precision_std: 0.02\n",
      "Sensitivity_mean: 0.836 ,Sensitivity_std: 0.07\n",
      "Specificity_mean: 0.71 ,Specificity_std: 0.07\n",
      "F1 score_mean: 0.241 ,F1 score_std: 0.03\n",
      "AUC_mean: 0.818 ,AUC_std: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1186, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn\\svm\\_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83228784 0.83038222 0.82945926 0.82898444 0.8286275\n",
      " 0.82832377 0.82811562 0.82794378 0.82790032 0.82779569        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "accuracy_all_list=[]\n",
    "precision_all_list=[]\n",
    "sensitivity_all_list=[]\n",
    "specificity_all_list=[]\n",
    "f1score_all_list=[]\n",
    "auc_all_list=[]\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    #Split the data (split into 80% training data & 20% testing data) (lock seed) \n",
    "    x_train,x_test,y_train,y_test=train_test_split(scaled_x,scaled_y,test_size=0.2,random_state=i)\n",
    "\n",
    "    # Initializing Classifiers\n",
    "    clf1 = LogisticRegression(penalty='l1',solver='liblinear',random_state=4)\n",
    "\n",
    "\n",
    "    # Setting up the parameter grids\n",
    "    param_grid1 = [{'C': list(range(0, 11)) + [None]}]\n",
    "\n",
    "    # K fold cross-validation\n",
    "    cross_val=KFold(n_splits=5,shuffle=True,random_state=4)\n",
    "    \n",
    "    # using gridsearch for hyper-parameter tuning\n",
    "    gridS_model = GridSearchCV(estimator=clf1,\n",
    "                                param_grid=param_grid1,\n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1,\n",
    "                                cv=cross_val,\n",
    "                                verbose=0,\n",
    "                                refit=True)\n",
    "\n",
    "    #peforming gridsearch & save each models training result\n",
    "    gridS_model.fit(x_train, y_train) \n",
    "    training_score=gridS_model.best_score_  \n",
    "    best_parameter=gridS_model.best_params_\n",
    "    train_model=gridS_model.best_estimator_\n",
    "    \n",
    "    \n",
    "    #print training result\n",
    "    print('Round',i)\n",
    "    print('random_state=',i)\n",
    "    print('Training score:',training_score)\n",
    "    print('Best Hyper-parameter set:',best_parameter)\n",
    "    \n",
    "    # Get model perdiction\n",
    "    proba=train_model.predict_proba(x_test)[:, 1]\n",
    "    auc_value = roc_auc_score(y_test, proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, proba, pos_label=1)\n",
    "    #caculate Youden's J statistic\n",
    "    J_score=tpr-fpr\n",
    "    best_JTH_cutpoint_index=np.argmax(J_score)\n",
    "    best_JS_threshold=thresholds[best_JTH_cutpoint_index]\n",
    "\n",
    "    # Calculate performance\n",
    "    final_prediction=(proba >= best_JS_threshold).astype('int')\n",
    "    confusion = confusion_matrix(y_test,final_prediction)\n",
    "    TP=confusion[1,1]\n",
    "    TN=confusion[0,0]\n",
    "    FP=confusion[0,1]\n",
    "    FN=confusion[1,0]\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(FP+TN)\n",
    "    precision=TP/(TP+FP)\n",
    "    f1score=2*(precision*sensitivity)/(precision+sensitivity)\n",
    "    \n",
    "\n",
    "    #print results\n",
    "    print('Testing results with best threshold')\n",
    "    print('===================================')\n",
    "    print('Accuracy:   ',round(accuracy,3))\n",
    "    print('Precision:  ',round(precision,3))\n",
    "    print('Sensitivity:',round(sensitivity,3))\n",
    "    print('Specificity:',round(specificity,3))\n",
    "    print('F1 score:   ',round(f1score,3))\n",
    "    print('AUC:        ',round(auc_value,3))\n",
    "    print('ThresHold:  ',best_JS_threshold)\n",
    "    print('-----------------------------------')\n",
    "    print(confusion)\n",
    "    print('---------------------------------------')\n",
    "    print('---------------------------------------\\n\\n')\n",
    "    \n",
    "#     #plot ROC fig with exist package module\n",
    "#     roc_fig=plot_roc_curve(train_model, x_test, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    accuracy_all=[round(accuracy,3)]\n",
    "    for a in accuracy_all:\n",
    "        accuracy_all_list+=[a]\n",
    "        \n",
    "    precision_all=[round(precision,3)]\n",
    "    for a in precision_all:\n",
    "        precision_all_list+=[a]\n",
    "    \n",
    "    sensitivity_all=[round(sensitivity,3)]\n",
    "    for a in sensitivity_all:\n",
    "        sensitivity_all_list+=[a]\n",
    "        \n",
    "    specificity_all=[round(specificity,3)]\n",
    "    for a in specificity_all:\n",
    "        specificity_all_list+=[a]\n",
    "        \n",
    "    f1score_all=[round(f1score,3)]\n",
    "    for a in f1score_all:\n",
    "        f1score_all_list+=[a]\n",
    "        \n",
    "    auc_all=[round(auc_value,3)]\n",
    "    for a in auc_all:\n",
    "        auc_all_list+=[a]\n",
    "\n",
    "\n",
    "best_Accuracy=max(accuracy_all_list)\n",
    "best_round=accuracy_all_list.index(best_Accuracy)+1\n",
    "print('Best:',best_Accuracy)\n",
    "print('Best Round:',best_round)\n",
    "print('---------------------------------------')\n",
    "print('Accuracy_mean:',round(np.mean(accuracy_all_list),3),',Accuracy_std:',round(np.std(accuracy_all_list),2))\n",
    "print('Precision_mean:',round(np.mean(precision_all_list),3),',Precision_std:',round(np.std(precision_all_list),2))\n",
    "print('Sensitivity_mean:',round(np.mean(sensitivity_all_list),3),',Sensitivity_std:',round(np.std(sensitivity_all_list),2))\n",
    "print('Specificity_mean:',round(np.mean(specificity_all_list),3),',Specificity_std:',round(np.std(specificity_all_list),2))\n",
    "print('F1 score_mean:',round(np.mean(f1score_all_list),3),',F1 score_std:',round(np.std(f1score_all_list),2))\n",
    "print('AUC_mean:',round(np.mean(auc_all_list),3),',AUC_std:',round(np.std(auc_all_list),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500e039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', random_state=4, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(scaled_x,scaled_y,test_size=0.2,random_state=7)\n",
    "model=LogisticRegression(penalty='l1',solver='liblinear',C=1,random_state=4)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a3c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance\n",
      "----------------------------------------------\n",
      "X2 \t  Feature_Imp= 4.85768\n",
      "X8 \t  Feature_Imp= 0.72156\n",
      "X9 \t  Feature_Imp= 0.00000\n",
      "X1_1 \t  Feature_Imp= -0.15472\n",
      "X1_2 \t  Feature_Imp= 0.00000\n",
      "X3_0 \t  Feature_Imp= -0.51649\n",
      "X3_1 \t  Feature_Imp= 0.00000\n",
      "X4_0 \t  Feature_Imp= -0.51339\n",
      "X4_1 \t  Feature_Imp= 0.00000\n",
      "X5_0 \t  Feature_Imp= 0.00000\n",
      "X5_1 \t  Feature_Imp= -0.11714\n",
      "X6_1 \t  Feature_Imp= 0.00000\n",
      "X6_2 \t  Feature_Imp= 0.00000\n",
      "X6_3 \t  Feature_Imp= 0.14132\n",
      "X6_4 \t  Feature_Imp= -0.12770\n",
      "X6_5 \t  Feature_Imp= 0.00000\n",
      "X7_1 \t  Feature_Imp= 0.00000\n",
      "X7_2 \t  Feature_Imp= -0.00515\n",
      "X10_1 \t  Feature_Imp= -0.31461\n",
      "X10_2 \t  Feature_Imp= -0.25167\n",
      "X10_3 \t  Feature_Imp= 0.00000\n",
      "\n",
      "\n",
      "Feature ranking\n",
      "----------------------------------------------\n",
      " 1) X2                             4.858\n",
      " 2) X8                             0.722\n",
      " 3) X6_3                           0.141\n",
      " 4) X6_1                           0.000\n",
      " 5) X9                             0.000\n",
      " 6) X1_2                           0.000\n",
      " 7) X3_1                           0.000\n",
      " 8) X4_1                           0.000\n",
      " 9) X5_0                           0.000\n",
      "10) X10_3                          0.000\n",
      "11) X6_2                           0.000\n",
      "12) X6_5                           0.000\n",
      "13) X7_1                           0.000\n",
      "14) X7_2                           -0.005\n",
      "15) X5_1                           -0.117\n",
      "16) X6_4                           -0.128\n",
      "17) X1_1                           -0.155\n",
      "18) X10_2                          -0.252\n",
      "19) X10_1                          -0.315\n",
      "20) X4_0                           -0.513\n",
      "21) X3_0                           -0.516\n"
     ]
    }
   ],
   "source": [
    "importance=model.coef_[0]\n",
    "importance_sort = np.argsort(importance)[::-1]\n",
    "df_col = dummied_new_df.columns[0:]\n",
    "print('Feature Importance')\n",
    "print('----------------------------------------------')\n",
    "for i,v in enumerate(importance):\n",
    "    df_columns=df_col[i]\n",
    "    print('%s \\t  Feature_Imp= %.5f' % (df_columns,v))\n",
    "print('\\n')    \n",
    "print('Feature ranking')\n",
    "print('----------------------------------------------')\n",
    "    \n",
    "# 依序迭代出重要特徵\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(f\"{f+1:>2d}) {df_col[importance_sort[f]]:<30s} {importance[importance_sort[f]]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
