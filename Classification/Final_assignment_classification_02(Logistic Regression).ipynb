{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598ff010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages always been used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preprocessing useful function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Data scaling\n",
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function for spilting training & testing data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Function for hyper-parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Functions for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c5853",
   "metadata": {},
   "source": [
    "# 3. Data scaling with minimax technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5439a552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X1_1</th>\n",
       "      <th>X1_2</th>\n",
       "      <th>X3_0</th>\n",
       "      <th>X3_1</th>\n",
       "      <th>X4_0</th>\n",
       "      <th>X4_1</th>\n",
       "      <th>X5_0</th>\n",
       "      <th>...</th>\n",
       "      <th>X6_3</th>\n",
       "      <th>X6_4</th>\n",
       "      <th>X6_5</th>\n",
       "      <th>X7_1</th>\n",
       "      <th>X7_2</th>\n",
       "      <th>X10_1</th>\n",
       "      <th>X10_2</th>\n",
       "      <th>X10_3</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>82</td>\n",
       "      <td>71.97</td>\n",
       "      <td>28.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>57</td>\n",
       "      <td>77.93</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>81</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>35</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>51</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3425 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X2      X8    X9  X1_1  X1_2  X3_0  X3_1  X4_0  X4_1  X5_0  ...  X6_3  \\\n",
       "0     67  228.69  36.6     1     0     1     0     0     1     0  ...     1   \n",
       "1     80  105.92  32.5     1     0     1     0     0     1     0  ...     1   \n",
       "2     49  171.23  34.4     0     1     1     0     1     0     0  ...     1   \n",
       "3     79  174.12  24.0     0     1     0     1     1     0     0  ...     0   \n",
       "4     81  186.21  29.0     1     0     1     0     1     0     0  ...     1   \n",
       "...   ..     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "3420  82   71.97  28.3     1     0     0     1     1     0     0  ...     0   \n",
       "3421  57   77.93  21.7     0     1     1     0     1     0     0  ...     1   \n",
       "3422  81  125.20  40.0     0     1     1     0     1     0     0  ...     0   \n",
       "3423  35   82.99  30.6     0     1     1     0     1     0     0  ...     0   \n",
       "3424  51  166.29  25.6     1     0     1     0     1     0     0  ...     1   \n",
       "\n",
       "      X6_4  X6_5  X7_1  X7_2  X10_1  X10_2  X10_3  Y_0  Y_1  \n",
       "0        0     0     0     1      0      1      0    0    1  \n",
       "1        0     0     1     0      1      0      0    0    1  \n",
       "2        0     0     0     1      0      0      1    0    1  \n",
       "3        1     0     1     0      1      0      0    0    1  \n",
       "4        0     0     0     1      0      1      0    0    1  \n",
       "...    ...   ...   ...   ...    ...    ...    ...  ...  ...  \n",
       "3420     1     0     1     0      1      0      0    1    0  \n",
       "3421     0     0     1     0      1      0      0    1    0  \n",
       "3422     1     0     0     1      1      0      0    1    0  \n",
       "3423     1     0     1     0      1      0      0    1    0  \n",
       "3424     0     0     1     0      0      1      0    1    0  \n",
       "\n",
       "[3425 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data(sometimes need to use \"/\")\n",
    "dummied_new_df = pd.read_csv('C:/Users/user/Desktop/Final_assignment/Data/中風_deleteNA_dummies.csv')\n",
    "dummied_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64c8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X1_1</th>\n",
       "      <th>X1_2</th>\n",
       "      <th>X3_0</th>\n",
       "      <th>X3_1</th>\n",
       "      <th>X4_0</th>\n",
       "      <th>X4_1</th>\n",
       "      <th>X5_0</th>\n",
       "      <th>...</th>\n",
       "      <th>X6_3</th>\n",
       "      <th>X6_4</th>\n",
       "      <th>X6_5</th>\n",
       "      <th>X7_1</th>\n",
       "      <th>X7_2</th>\n",
       "      <th>X10_1</th>\n",
       "      <th>X10_2</th>\n",
       "      <th>X10_3</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.311801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.234512</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.536008</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.605161</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X2        X8        X9  X1_1  X1_2  X3_0  X3_1  X4_0  X4_1  X5_0  \\\n",
       "0  0.791667  0.801265  0.311801   1.0   0.0   1.0   0.0   0.0   1.0   0.0   \n",
       "1  0.972222  0.234512  0.260870   1.0   0.0   1.0   0.0   0.0   1.0   0.0   \n",
       "2  0.541667  0.536008  0.284472   0.0   1.0   1.0   0.0   1.0   0.0   0.0   \n",
       "3  0.958333  0.549349  0.155280   0.0   1.0   0.0   1.0   1.0   0.0   0.0   \n",
       "4  0.986111  0.605161  0.217391   1.0   0.0   1.0   0.0   1.0   0.0   0.0   \n",
       "\n",
       "   ...  X6_3  X6_4  X6_5  X7_1  X7_2  X10_1  X10_2  X10_3  Y_0  Y_1  \n",
       "0  ...   1.0   0.0   0.0   0.0   1.0    0.0    1.0    0.0  0.0  1.0  \n",
       "1  ...   1.0   0.0   0.0   1.0   0.0    1.0    0.0    0.0  0.0  1.0  \n",
       "2  ...   1.0   0.0   0.0   0.0   1.0    0.0    0.0    1.0  0.0  1.0  \n",
       "3  ...   0.0   1.0   0.0   1.0   0.0    1.0    0.0    0.0  0.0  1.0  \n",
       "4  ...   1.0   0.0   0.0   0.0   1.0    0.0    1.0    0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minimax scaling\n",
    "MMscaler=MinMaxScaler(feature_range=(0, 1))\n",
    "scaling=MMscaler.fit_transform(dummied_new_df)\n",
    "scaled_data=pd.DataFrame(data=scaling)\n",
    "scaled_data.columns=['X2','X8','X9','X1_1','X1_2','X3_0','X3_1','X4_0','X4_1','X5_0','X5_1','X6_1','X6_2','X6_3','X6_4','X6_5','X7_1','X7_2','X10_1','X10_2','X10_3','Y_0','Y_1'\n",
    "]\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd2ee2",
   "metadata": {},
   "source": [
    "# 4. Set dependent variable(Y or target) & independent variable(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22f3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set x (make prediction) with minimax\n",
    "scaled_x=scaled_data.drop(['Y_0','Y_1'],axis=1).copy()\n",
    "#set y (want to predict)\n",
    "scaled_y=scaled_data['Y_1'].copy()\n",
    "scaled_y=scaled_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12756a12",
   "metadata": {},
   "source": [
    "# 5.  Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14d397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.80244965 0.80244965 0.80244965 0.80244965 0.80244965 0.80244965\n",
      " 0.80244965 0.80244965 0.80244965 0.80244965        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.81922486 0.81922486 0.81922486 0.81922486 0.81922486 0.81922486\n",
      " 0.81922486 0.81922486 0.81922486 0.81922486        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "random_state= 1\n",
      "Training score: 0.8024496543861513\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.724\n",
      "Precision:   0.149\n",
      "Sensitivity: 0.971\n",
      "Specificity: 0.711\n",
      "F1 score:    0.259\n",
      "AUC:         0.899\n",
      "ThresHold:   0.0493918679742084\n",
      "-----------------------------------\n",
      "[[463 188]\n",
      " [  1  33]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 2\n",
      "random_state= 2\n",
      "Training score: 0.8192248587581792\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.771\n",
      "Precision:   0.188\n",
      "Sensitivity: 0.773\n",
      "Specificity: 0.771\n",
      "F1 score:    0.302\n",
      "AUC:         0.833\n",
      "ThresHold:   0.053346780681199205\n",
      "-----------------------------------\n",
      "[[494 147]\n",
      " [ 10  34]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83162563 0.83162563 0.83162563 0.83162563 0.83162563 0.83162563\n",
      " 0.83162563 0.83162563 0.83162563 0.83162563        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83043743 0.83043743 0.83043743 0.83043743 0.83043743 0.83043743\n",
      " 0.83043743 0.83043743 0.83043743 0.83043743        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3\n",
      "random_state= 3\n",
      "Training score: 0.8316256300548932\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.711\n",
      "Precision:   0.12\n",
      "Sensitivity: 0.788\n",
      "Specificity: 0.707\n",
      "F1 score:    0.208\n",
      "AUC:         0.79\n",
      "ThresHold:   0.05653486356268741\n",
      "-----------------------------------\n",
      "[[461 191]\n",
      " [  7  26]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 4\n",
      "random_state= 4\n",
      "Training score: 0.830437434269407\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.616\n",
      "Precision:   0.103\n",
      "Sensitivity: 0.909\n",
      "Specificity: 0.601\n",
      "F1 score:    0.186\n",
      "AUC:         0.791\n",
      "ThresHold:   0.028702499270449655\n",
      "-----------------------------------\n",
      "[[392 260]\n",
      " [  3  30]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82276107 0.82276107 0.82276107 0.82276107 0.82276107 0.82276107\n",
      " 0.82276107 0.82276107 0.82276107 0.82276107        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82227281 0.82227281 0.82227281 0.82227281 0.82227281 0.82227281\n",
      " 0.82227281 0.82227281 0.82227281 0.82227281        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5\n",
      "random_state= 5\n",
      "Training score: 0.8227610737863916\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.74\n",
      "Precision:   0.141\n",
      "Sensitivity: 0.778\n",
      "Specificity: 0.738\n",
      "F1 score:    0.239\n",
      "AUC:         0.792\n",
      "ThresHold:   0.05212824419982112\n",
      "-----------------------------------\n",
      "[[479 170]\n",
      " [  8  28]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 6\n",
      "random_state= 6\n",
      "Training score: 0.8222728140673148\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.769\n",
      "Precision:   0.183\n",
      "Sensitivity: 0.75\n",
      "Specificity: 0.771\n",
      "F1 score:    0.295\n",
      "AUC:         0.814\n",
      "ThresHold:   0.05904312995663795\n",
      "-----------------------------------\n",
      "[[494 147]\n",
      " [ 11  33]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.81724652 0.81724652 0.81724652 0.81724652 0.81724652 0.81724652\n",
      " 0.81724652 0.81724652 0.81724652 0.81724652        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.8242847 0.8242847 0.8242847 0.8242847 0.8242847 0.8242847 0.8242847\n",
      " 0.8242847 0.8242847 0.8242847       nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 7\n",
      "random_state= 7\n",
      "Training score: 0.8172465194674874\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.82\n",
      "Precision:   0.152\n",
      "Sensitivity: 0.778\n",
      "Specificity: 0.822\n",
      "F1 score:    0.255\n",
      "AUC:         0.843\n",
      "ThresHold:   0.1052130949301379\n",
      "-----------------------------------\n",
      "[[541 117]\n",
      " [  6  21]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 8\n",
      "random_state= 8\n",
      "Training score: 0.8242846959634598\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.712\n",
      "Precision:   0.136\n",
      "Sensitivity: 0.833\n",
      "Specificity: 0.706\n",
      "F1 score:    0.233\n",
      "AUC:         0.804\n",
      "ThresHold:   0.04848443702303066\n",
      "-----------------------------------\n",
      "[[458 191]\n",
      " [  6  30]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 9\n",
      "random_state= 9\n",
      "Training score: 0.8246850666653742\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.634\n",
      "Precision:   0.114\n",
      "Sensitivity: 0.914\n",
      "Specificity: 0.618\n",
      "F1 score:    0.203\n",
      "AUC:         0.818\n",
      "ThresHold:   0.03126276091178395\n",
      "-----------------------------------\n",
      "[[402 248]\n",
      " [  3  32]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Round 10\n",
      "random_state= 10\n",
      "Training score: 0.8272170929251772\n",
      "Best Hyper-parameter set: {'C': 1}\n",
      "Testing results with best threshold\n",
      "===================================\n",
      "Accuracy:    0.728\n",
      "Precision:   0.146\n",
      "Sensitivity: 0.75\n",
      "Specificity: 0.727\n",
      "F1 score:    0.244\n",
      "AUC:         0.788\n",
      "ThresHold:   0.05666613091884529\n",
      "-----------------------------------\n",
      "[[469 176]\n",
      " [ 10  30]]\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Best: 0.82\n",
      "Best Round: 7\n",
      "---------------------------------------\n",
      "Accuracy_mean: 0.722 ,Accuracy_std: 0.06\n",
      "Precision_mean: 0.143 ,Precision_std: 0.03\n",
      "Sensitivity_mean: 0.824 ,Sensitivity_std: 0.07\n",
      "Specificity_mean: 0.717 ,Specificity_std: 0.06\n",
      "F1 score_mean: 0.242 ,F1 score_std: 0.04\n",
      "AUC_mean: 0.817 ,AUC_std: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82468507 0.82468507 0.82468507 0.82468507 0.82468507 0.82468507\n",
      " 0.82468507 0.82468507 0.82468507 0.82468507        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82721709 0.82721709 0.82721709 0.82721709 0.82721709 0.82721709\n",
      " 0.82721709 0.82721709 0.82721709 0.82721709        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "accuracy_all_list=[]\n",
    "precision_all_list=[]\n",
    "sensitivity_all_list=[]\n",
    "specificity_all_list=[]\n",
    "f1score_all_list=[]\n",
    "auc_all_list=[]\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    #Split the data (split into 80% training data & 20% testing data) (lock seed) \n",
    "    x_train,x_test,y_train,y_test=train_test_split(scaled_x,scaled_y,test_size=0.2,random_state=i)\n",
    "\n",
    "    # Initializing Classifiers\n",
    "    clf1 = LogisticRegression(penalty='none',random_state=4)\n",
    "\n",
    "    # Setting up the parameter grids\n",
    "    param_grid1 = [{'C': list(range(1, 11)) + [None]}]\n",
    "\n",
    "    # K fold cross-validation\n",
    "    cross_val=KFold(n_splits=5,shuffle=True,random_state=4)\n",
    "    \n",
    "    # using gridsearch for hyper-parameter tuning\n",
    "    gridS_model = GridSearchCV(estimator=clf1,\n",
    "                                param_grid=param_grid1,\n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1,\n",
    "                                cv=cross_val,\n",
    "                                verbose=0,\n",
    "                                refit=True)\n",
    "\n",
    "    #peforming gridsearch & save each models training result\n",
    "    gridS_model.fit(x_train, y_train) \n",
    "    training_score=gridS_model.best_score_  \n",
    "    best_parameter=gridS_model.best_params_\n",
    "    train_model=gridS_model.best_estimator_\n",
    "    \n",
    "    \n",
    "    #print training result\n",
    "    print('Round',i)\n",
    "    print('random_state=',i)\n",
    "    print('Training score:',training_score)\n",
    "    print('Best Hyper-parameter set:',best_parameter)\n",
    "    \n",
    "    # Get model perdiction\n",
    "    proba=train_model.predict_proba(x_test)[:, 1]\n",
    "    auc_value = roc_auc_score(y_test, proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, proba, pos_label=1)\n",
    "    #caculate Youden's J statistic\n",
    "    J_score=tpr-fpr\n",
    "    best_JTH_cutpoint_index=np.argmax(J_score)\n",
    "    best_JS_threshold=thresholds[best_JTH_cutpoint_index]\n",
    "\n",
    "    # Calculate performance\n",
    "    final_prediction=(proba >= best_JS_threshold).astype('int')\n",
    "    confusion = confusion_matrix(y_test,final_prediction)\n",
    "    TP=confusion[1,1]\n",
    "    TN=confusion[0,0]\n",
    "    FP=confusion[0,1]\n",
    "    FN=confusion[1,0]\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(FP+TN)\n",
    "    precision=TP/(TP+FP)\n",
    "    f1score=2*(precision*sensitivity)/(precision+sensitivity)\n",
    "    \n",
    "\n",
    "    #print results\n",
    "    print('Testing results with best threshold')\n",
    "    print('===================================')\n",
    "    print('Accuracy:   ',round(accuracy,3))\n",
    "    print('Precision:  ',round(precision,3))\n",
    "    print('Sensitivity:',round(sensitivity,3))\n",
    "    print('Specificity:',round(specificity,3))\n",
    "    print('F1 score:   ',round(f1score,3))\n",
    "    print('AUC:        ',round(auc_value,3))\n",
    "    print('ThresHold:  ',best_JS_threshold)\n",
    "    print('-----------------------------------')\n",
    "    print(confusion)\n",
    "    print('---------------------------------------')\n",
    "    print('---------------------------------------\\n\\n')\n",
    "    \n",
    "#     #plot ROC fig with exist package module\n",
    "#     roc_fig=plot_roc_curve(train_model, x_test, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    accuracy_all=[round(accuracy,3)]\n",
    "    for a in accuracy_all:\n",
    "        accuracy_all_list+=[a]\n",
    "        \n",
    "    precision_all=[round(precision,3)]\n",
    "    for a in precision_all:\n",
    "        precision_all_list+=[a]\n",
    "    \n",
    "    sensitivity_all=[round(sensitivity,3)]\n",
    "    for a in sensitivity_all:\n",
    "        sensitivity_all_list+=[a]\n",
    "        \n",
    "    specificity_all=[round(specificity,3)]\n",
    "    for a in specificity_all:\n",
    "        specificity_all_list+=[a]\n",
    "        \n",
    "    f1score_all=[round(f1score,3)]\n",
    "    for a in f1score_all:\n",
    "        f1score_all_list+=[a]\n",
    "        \n",
    "    auc_all=[round(auc_value,3)]\n",
    "    for a in auc_all:\n",
    "        auc_all_list+=[a]\n",
    "\n",
    "\n",
    "best_Accuracy=max(accuracy_all_list)\n",
    "best_round=accuracy_all_list.index(best_Accuracy)+1\n",
    "print('Best:',best_Accuracy)\n",
    "print('Best Round:',best_round)\n",
    "print('---------------------------------------')\n",
    "print('Accuracy_mean:',round(np.mean(accuracy_all_list),3),',Accuracy_std:',round(np.std(accuracy_all_list),2))\n",
    "print('Precision_mean:',round(np.mean(precision_all_list),3),',Precision_std:',round(np.std(precision_all_list),2))\n",
    "print('Sensitivity_mean:',round(np.mean(sensitivity_all_list),3),',Sensitivity_std:',round(np.std(sensitivity_all_list),2))\n",
    "print('Specificity_mean:',round(np.mean(specificity_all_list),3),',Specificity_std:',round(np.std(specificity_all_list),2))\n",
    "print('F1 score_mean:',round(np.mean(f1score_all_list),3),',F1 score_std:',round(np.std(f1score_all_list),2))\n",
    "print('AUC_mean:',round(np.mean(auc_all_list),3),',AUC_std:',round(np.std(auc_all_list),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32eb38d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, penalty='none', random_state=4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(scaled_x,scaled_y,test_size=0.2,random_state=7)\n",
    "model = LogisticRegression(penalty='none',C=1,random_state=4)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09af6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance\n",
      "----------------------------------------------\n",
      "X2 \t  Feature_Imp= 5.28520\n",
      "X8 \t  Feature_Imp= 0.88051\n",
      "X9 \t  Feature_Imp= -0.54402\n",
      "X1_1 \t  Feature_Imp= -1.72199\n",
      "X1_2 \t  Feature_Imp= -1.53783\n",
      "X3_0 \t  Feature_Imp= -1.88058\n",
      "X3_1 \t  Feature_Imp= -1.37924\n",
      "X4_0 \t  Feature_Imp= -1.85489\n",
      "X4_1 \t  Feature_Imp= -1.40493\n",
      "X5_0 \t  Feature_Imp= -1.54407\n",
      "X5_1 \t  Feature_Imp= -1.71575\n",
      "X6_1 \t  Feature_Imp= -16.79456\n",
      "X6_2 \t  Feature_Imp= -5.33805\n",
      "X6_3 \t  Feature_Imp= 6.47546\n",
      "X6_4 \t  Feature_Imp= 6.12449\n",
      "X6_5 \t  Feature_Imp= 6.27283\n",
      "X7_1 \t  Feature_Imp= -1.61549\n",
      "X7_2 \t  Feature_Imp= -1.64433\n",
      "X10_1 \t  Feature_Imp= -1.23718\n",
      "X10_2 \t  Feature_Imp= -1.18531\n",
      "X10_3 \t  Feature_Imp= -0.83733\n",
      "\n",
      "\n",
      "Feature ranking\n",
      "----------------------------------------------\n",
      " 1) X6_3                           6.475\n",
      " 2) X6_5                           6.273\n",
      " 3) X6_4                           6.124\n",
      " 4) X2                             5.285\n",
      " 5) X8                             0.881\n",
      " 6) X9                             -0.544\n",
      " 7) X10_3                          -0.837\n",
      " 8) X10_2                          -1.185\n",
      " 9) X10_1                          -1.237\n",
      "10) X3_1                           -1.379\n",
      "11) X4_1                           -1.405\n",
      "12) X1_2                           -1.538\n",
      "13) X5_0                           -1.544\n",
      "14) X7_1                           -1.615\n",
      "15) X7_2                           -1.644\n",
      "16) X5_1                           -1.716\n",
      "17) X1_1                           -1.722\n",
      "18) X4_0                           -1.855\n",
      "19) X3_0                           -1.881\n",
      "20) X6_2                           -5.338\n",
      "21) X6_1                           -16.795\n"
     ]
    }
   ],
   "source": [
    "importance=model.coef_[0]\n",
    "importance_sort = np.argsort(importance)[::-1]\n",
    "df_col = dummied_new_df.columns[0:]\n",
    "print('Feature Importance')\n",
    "print('----------------------------------------------')\n",
    "for i,v in enumerate(importance):\n",
    "    df_columns=df_col[i]\n",
    "    print('%s \\t  Feature_Imp= %.5f' % (df_columns,v))\n",
    "print('\\n')    \n",
    "print('Feature ranking')\n",
    "print('----------------------------------------------')\n",
    "    \n",
    "# 依序迭代出重要特徵\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(f\"{f+1:>2d}) {df_col[importance_sort[f]]:<30s} {importance[importance_sort[f]]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46230c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
